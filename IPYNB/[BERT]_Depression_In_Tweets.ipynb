{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[BERT] Depression In Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQdYtyDBU180",
        "outputId": "052ed7c3-04d2-4954-dcbf-de1e2de6a287"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 12 06:43:18 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   64C    P8    33W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYO3Rb4s-8Tk",
        "outputId": "d30808ce-ba67-415c-d1d3-71b507c6666a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://tasnim7ahmed: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@github.com/tasnim7ahmed/Depression-In-Tweets.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hJvwHoPVNcG",
        "outputId": "ed4b495f-5521-462c-9407-6fb949394d2d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Depression-In-Tweets'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 82 (delta 31), reused 72 (delta 21), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r /content/Depression-In-Tweets/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5fKxDBwVamu",
        "outputId": "09836c38-7bc3-4cb6-8326-d916dcb2cdd0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 51.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 4.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 33.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 24.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 52.3 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Depression-In-Tweets/Scripts/train.py --epochs 10 --pretrained_model bert-base-uncased --dataset_path /content/Depression-In-Tweets/Dataset/ --model_path /content/Depression-In-Tweets/Models/ --output_path /content/Depression-In-Tweets/Output/ --figure_path /content/Depression-In-Tweets/Figures/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3TaH92ufV4pn",
        "outputId": "297518a8-f995-45b5-fa7b-49b774b6deaa"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'mild', 'non-depressed', 'moderate', 'severe'}\n",
            "train len - 24114, valid len - 8038, test len - 8039\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 2.02MB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 26.7kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 3.22MB/s]\n",
            "Downloading: 100% 570/570 [00:00<00:00, 662kB/s]\n",
            "Downloading: 100% 420M/420M [00:11<00:00, 39.2MB/s]\n",
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "109531844\n",
            "---Starting Training---\n",
            "Epoch 1/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.72]\n",
            "Epoch 1 --- Training loss: 0.7201306657811296 Training accuracy: 0.7143\n",
            "100% 252/252 [02:11<00:00,  1.92it/s]\n",
            "Epoch 1 --- Validation loss: 0.5836655943403168 Validation accuracy: 0.7421\n",
            "Epoch 2/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.573]\n",
            "Epoch 2 --- Training loss: 0.5726888761645682 Training accuracy: 0.7596\n",
            "100% 252/252 [02:11<00:00,  1.91it/s]\n",
            "Epoch 2 --- Validation loss: 0.5538439660200051 Validation accuracy: 0.7784\n",
            "Epoch 3/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.514]\n",
            "Epoch 3 --- Training loss: 0.5135324700915845 Training accuracy: 0.796\n",
            "100% 252/252 [02:11<00:00,  1.92it/s]\n",
            "Epoch 3 --- Validation loss: 0.5298011896037866 Validation accuracy: 0.7753\n",
            "Epoch 4/10\n",
            "----------\n",
            "100% 1508/1508 [18:49<00:00,  1.33it/s, loss=0.432]\n",
            "Epoch 4 --- Training loss: 0.43152818221608746 Training accuracy: 0.8429\n",
            "100% 252/252 [02:10<00:00,  1.93it/s]\n",
            "Epoch 4 --- Validation loss: 0.6125173838365645 Validation accuracy: 0.7705\n",
            "Epoch 5/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.35]\n",
            "Epoch 5 --- Training loss: 0.35021530511228255 Training accuracy: 0.8825\n",
            "100% 252/252 [02:11<00:00,  1.92it/s]\n",
            "Epoch 5 --- Validation loss: 0.6574481283092782 Validation accuracy: 0.7902\n",
            "Epoch 6/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.289]\n",
            "Epoch 6 --- Training loss: 0.2891110578571651 Training accuracy: 0.9097\n",
            "100% 252/252 [02:11<00:00,  1.91it/s]\n",
            "Epoch 6 --- Validation loss: 0.6964016423693725 Validation accuracy: 0.7873\n",
            "Epoch 7/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.236]\n",
            "Epoch 7 --- Training loss: 0.23618020233883466 Training accuracy: 0.9329\n",
            "100% 252/252 [02:11<00:00,  1.92it/s]\n",
            "Epoch 7 --- Validation loss: 0.8318533143472104 Validation accuracy: 0.7866\n",
            "Epoch 8/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.196]\n",
            "Epoch 8 --- Training loss: 0.19556196940697196 Training accuracy: 0.9477\n",
            "100% 252/252 [02:11<00:00,  1.91it/s]\n",
            "Epoch 8 --- Validation loss: 0.8708864095369502 Validation accuracy: 0.7841\n",
            "Epoch 9/10\n",
            "----------\n",
            "100% 1508/1508 [18:51<00:00,  1.33it/s, loss=0.157]\n",
            "Epoch 9 --- Training loss: 0.15708769907908074 Training accuracy: 0.9607\n",
            "100% 252/252 [02:11<00:00,  1.92it/s]\n",
            "Epoch 9 --- Validation loss: 0.8752376084762906 Validation accuracy: 0.7867\n",
            "Epoch 10/10\n",
            "----------\n",
            "100% 1508/1508 [18:39<00:00,  1.35it/s, loss=0.136]\n",
            "Epoch 10 --- Training loss: 0.13596630990641087 Training accuracy: 0.9676\n",
            "100% 252/252 [02:10<00:00,  1.94it/s]\n",
            "Epoch 10 --- Validation loss: 0.8870847968842893 Validation accuracy: 0.7858\n",
            "\n",
            "---History---\n",
            "defaultdict(<class 'list'>, {'train_acc': [0.7143, 0.7596, 0.796, 0.8429, 0.8825, 0.9097, 0.9329, 0.9477, 0.9607, 0.9676], 'train_loss': [0.7201306657811296, 0.5726888761645682, 0.5135324700915845, 0.43152818221608746, 0.35021530511228255, 0.2891110578571651, 0.23618020233883466, 0.19556196940697196, 0.15708769907908074, 0.13596630990641087], 'val_acc': [0.7421, 0.7784, 0.7753, 0.7705, 0.7902, 0.7873, 0.7866, 0.7841, 0.7867, 0.7858], 'val_loss': [0.5836655943403168, 0.5538439660200051, 0.5298011896037866, 0.6125173838365645, 0.6574481283092782, 0.6964016423693725, 0.8318533143472104, 0.8708864095369502, 0.8752376084762906, 0.8870847968842893]})\n",
            "##################################### Testing ############################################\n",
            "\n",
            "Evaluating: ---bert-base-uncased---\n",
            "\n",
            "100% 252/252 [02:10<00:00,  1.94it/s]\n",
            "Output length --- 8039, Prediction length --- 8039\n",
            "Accuracy: 0.7912675705933574\n",
            "Mcc Score: 0.33444753204870525\n",
            "Precision: 0.7799803096934581\n",
            "Recall: 0.7912675705933574\n",
            "F1_score: 0.7842761707495546\n",
            "classification_report:                precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8807    0.9056    0.8929      6480\n",
            "           1     0.3505    0.3575    0.3539      1049\n",
            "           2     0.3474    0.2044    0.2574       362\n",
            "           3     0.4731    0.2973    0.3651       148\n",
            "\n",
            "    accuracy                         0.7913      8039\n",
            "   macro avg     0.5129    0.4412    0.4674      8039\n",
            "weighted avg     0.7800    0.7913    0.7843      8039\n",
            "\n",
            "[[5868  526   51   35]\n",
            " [ 601  375   63   10]\n",
            " [ 140  144   74    4]\n",
            " [  54   25   25   44]]\n",
            "0.9340289470677277\n",
            "##################################### Task End ############################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zip and Download Models and Test Outputs after Training**\n"
      ],
      "metadata": {
        "id": "2g-t1QhQZ5OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/Research/Experiments/DepressionInTweets/BERT/Models.zip /content/Depression-In-Tweets/Models\n",
        "!zip -r /content/drive/MyDrive/Research/Experiments/DepressionInTweets/BERT/Output.zip /content/Depression-In-Tweets/Output\n",
        "!zip -r /content/drive/MyDrive/Research/Experiments/DepressionInTweets/BERT/Figures.zip /content/Depression-In-Tweets/Figures"
      ],
      "metadata": {
        "id": "xAvvm_M4W244",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13994c19-d865-4c28-d546-68d009b3af8b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Depression-In-Tweets/Models/ (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Models/bert-base-uncased_Best_Val_Acc.bin (deflated 7%)\n",
            "  adding: content/Depression-In-Tweets/Models/.gitkeep (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Output/ (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Output/bert-base-uncased---test_acc---0.7912675705933574.csv (deflated 61%)\n",
            "  adding: content/Depression-In-Tweets/Output/.gitkeep (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Figures/ (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Figures/bert-base-uncased---loss---.pdf (deflated 33%)\n",
            "  adding: content/Depression-In-Tweets/Figures/bert-base-uncased---acc---.pdf (deflated 34%)\n",
            "  adding: content/Depression-In-Tweets/Figures/bert-base-uncased---roc_auc_curve---.pdf (deflated 13%)\n",
            "  adding: content/Depression-In-Tweets/Figures/.gitkeep (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "jUfbcHlCaADG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Depression-In-Tweets/Scripts/evaluate.py --dataset_path /content/Depression-In-Tweets/Dataset/ --model_path /content/Depression-In-Tweets/Models/ --output_path /content/Depression-In-Tweets/Output/ --figure_path /content/Depression-In-Tweets/Figures/"
      ],
      "metadata": {
        "id": "9dLlPw9waDhp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50c8aba7-c908-4876-e825-6c830e87ec4f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "\n",
            "Evaluating: ---bert-base-uncased---\n",
            "\n",
            " 45% 113/252 [00:59<01:12,  1.91it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Depression-In-Tweets/Scripts/evaluate.py\", line 80, in <module>\n",
            "    test_evaluate(test_df, test_data_loader, bert, device, pretrained_model=\"bert-base-uncased\")\n",
            "  File \"/content/Depression-In-Tweets/Scripts/evaluate.py\", line 22, in test_evaluate\n",
            "    y_pred, y_test, y_proba = test_eval_fn(test_data_loader, model, device, pretrained_model)\n",
            "  File \"/content/Depression-In-Tweets/Scripts/engine.py\", line 88, in test_eval_fn\n",
            "    val_losses.append(loss.item())\n",
            "KeyboardInterrupt\n"
          ]
        }
      ]
    }
  ]
}