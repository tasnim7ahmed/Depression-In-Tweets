{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[DistilBERT] Depression In Tweets.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "VQdYtyDBU180",
        "outputId": "dd3a0e55-4b9e-463d-dfa6-dfddf45f2573"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wed Jan 12 06:47:52 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   46C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "FYO3Rb4s-8Tk",
        "outputId": "bc80cd46-4b69-4f21-edef-95febee98b24"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://tasnim7ahmed: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@github.com/tasnim7ahmed/Depression-In-Tweets.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "4hJvwHoPVNcG",
        "outputId": "57ff07df-d93d-4252-f9f8-ef433aa438e1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Depression-In-Tweets'...\n",
            "remote: Enumerating objects: 82, done.\u001b[K\n",
            "remote: Counting objects: 100% (82/82), done.\u001b[K\n",
            "remote: Compressing objects: 100% (55/55), done.\u001b[K\n",
            "remote: Total 82 (delta 31), reused 72 (delta 21), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (82/82), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q -r /content/Depression-In-Tweets/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "K5fKxDBwVamu",
        "outputId": "e069f229-9e40-48af-fb6b-c95574f1f86b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 3.4 MB 5.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 37.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 596 kB 50.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 35.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 50.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 67 kB 5.2 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Depression-In-Tweets/Scripts/train.py --epochs 10 --pretrained_model distilbert-base-uncased --dataset_path /content/Depression-In-Tweets/Dataset/ --model_path /content/Depression-In-Tweets/Models/ --output_path /content/Depression-In-Tweets/Output/ --figure_path /content/Depression-In-Tweets/Figures/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "3TaH92ufV4pn",
        "outputId": "1fde17fa-012d-460a-c797-a43837c71da6"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'severe', 'moderate', 'non-depressed', 'mild'}\n",
            "train len - 24114, valid len - 8038, test len - 8039\n",
            "Downloading: 100% 226k/226k [00:00<00:00, 1.98MB/s]\n",
            "Downloading: 100% 28.0/28.0 [00:00<00:00, 26.7kB/s]\n",
            "Downloading: 100% 455k/455k [00:00<00:00, 3.13MB/s]\n",
            "Downloading: 100% 483/483 [00:00<00:00, 430kB/s]\n",
            "Downloading: 100% 256M/256M [00:06<00:00, 42.0MB/s]\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_projector.bias', 'vocab_projector.weight', 'vocab_layer_norm.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "66412484\n",
            "---Starting Training---\n",
            "Epoch 1/10\n",
            "----------\n",
            "100% 1508/1508 [09:17<00:00,  2.71it/s, loss=0.707]\n",
            "Epoch 1 --- Training loss: 0.7070622129726473 Training accuracy: 0.7183\n",
            "100% 252/252 [01:04<00:00,  3.90it/s]\n",
            "Epoch 1 --- Validation loss: 0.5572142053454642 Validation accuracy: 0.7653\n",
            "Epoch 2/10\n",
            "----------\n",
            "100% 1508/1508 [09:18<00:00,  2.70it/s, loss=0.569]\n",
            "Epoch 2 --- Training loss: 0.5705283226381088 Training accuracy: 0.7619\n",
            "100% 252/252 [01:04<00:00,  3.89it/s]\n",
            "Epoch 2 --- Validation loss: 0.5322620199313239 Validation accuracy: 0.7845\n",
            "Epoch 3/10\n",
            "----------\n",
            "100% 1508/1508 [09:18<00:00,  2.70it/s, loss=0.508]\n",
            "Epoch 3 --- Training loss: 0.5073571290020443 Training accuracy: 0.7978\n",
            "100% 252/252 [01:05<00:00,  3.86it/s]\n",
            "Epoch 3 --- Validation loss: 0.534385811714899 Validation accuracy: 0.7848\n",
            "Epoch 4/10\n",
            "----------\n",
            "100% 1508/1508 [09:18<00:00,  2.70it/s, loss=0.436]\n",
            "Epoch 4 --- Training loss: 0.4355245667092245 Training accuracy: 0.8377\n",
            "100% 252/252 [01:04<00:00,  3.88it/s]\n",
            "Epoch 4 --- Validation loss: 0.5571357847915756 Validation accuracy: 0.7946\n",
            "Epoch 5/10\n",
            "----------\n",
            "100% 1508/1508 [09:18<00:00,  2.70it/s, loss=0.352]\n",
            "Epoch 5 --- Training loss: 0.35159658557248724 Training accuracy: 0.8786\n",
            "100% 252/252 [01:04<00:00,  3.90it/s]\n",
            "Epoch 5 --- Validation loss: 0.6010846519280993 Validation accuracy: 0.7909\n",
            "Epoch 6/10\n",
            "----------\n",
            "100% 1508/1508 [09:16<00:00,  2.71it/s, loss=0.289]\n",
            "Epoch 6 --- Training loss: 0.28835911582043733 Training accuracy: 0.9091\n",
            "100% 252/252 [01:04<00:00,  3.91it/s]\n",
            "Epoch 6 --- Validation loss: 0.7357872751142297 Validation accuracy: 0.7836\n",
            "Epoch 7/10\n",
            "----------\n",
            "100% 1508/1508 [09:16<00:00,  2.71it/s, loss=0.239]\n",
            "Epoch 7 --- Training loss: 0.23903047578626704 Training accuracy: 0.9299\n",
            "100% 252/252 [01:04<00:00,  3.93it/s]\n",
            "Epoch 7 --- Validation loss: 0.8219942451706008 Validation accuracy: 0.7846\n",
            "Epoch 8/10\n",
            "----------\n",
            "100% 1508/1508 [09:15<00:00,  2.71it/s, loss=0.196]\n",
            "Epoch 8 --- Training loss: 0.19622188073148164 Training accuracy: 0.9462\n",
            "100% 252/252 [01:04<00:00,  3.92it/s]\n",
            "Epoch 8 --- Validation loss: 0.8294535237290557 Validation accuracy: 0.7841\n",
            "Epoch 9/10\n",
            "----------\n",
            "100% 1508/1508 [09:15<00:00,  2.71it/s, loss=0.165]\n",
            "Epoch 9 --- Training loss: 0.16497020165878162 Training accuracy: 0.9561\n",
            "100% 252/252 [01:04<00:00,  3.92it/s]\n",
            "Epoch 9 --- Validation loss: 0.8928482034576258 Validation accuracy: 0.7805\n",
            "Epoch 10/10\n",
            "----------\n",
            "100% 1508/1508 [09:15<00:00,  2.71it/s, loss=0.146]\n",
            "Epoch 10 --- Training loss: 0.1463232680868644 Training accuracy: 0.9633\n",
            "100% 252/252 [01:04<00:00,  3.91it/s]\n",
            "Epoch 10 --- Validation loss: 0.8877621232753709 Validation accuracy: 0.7841\n",
            "\n",
            "---History---\n",
            "defaultdict(<class 'list'>, {'train_acc': [0.7183, 0.7619, 0.7978, 0.8377, 0.8786, 0.9091, 0.9299, 0.9462, 0.9561, 0.9633], 'train_loss': [0.7070622129726473, 0.5705283226381088, 0.5073571290020443, 0.4355245667092245, 0.35159658557248724, 0.28835911582043733, 0.23903047578626704, 0.19622188073148164, 0.16497020165878162, 0.1463232680868644], 'val_acc': [0.7653, 0.7845, 0.7848, 0.7946, 0.7909, 0.7836, 0.7846, 0.7841, 0.7805, 0.7841], 'val_loss': [0.5572142053454642, 0.5322620199313239, 0.534385811714899, 0.5571357847915756, 0.6010846519280993, 0.7357872751142297, 0.8219942451706008, 0.8294535237290557, 0.8928482034576258, 0.8877621232753709]})\n",
            "##################################### Testing ############################################\n",
            "\n",
            "Evaluating: ---distilbert-base-uncased---\n",
            "\n",
            "100% 252/252 [01:04<00:00,  3.92it/s]\n",
            "Output length --- 8039, Prediction length --- 8039\n",
            "Accuracy: 0.7963677074262968\n",
            "Mcc Score: 0.3449906019335966\n",
            "Precision: 0.7815983190106336\n",
            "Recall: 0.7963677074262968\n",
            "F1_score: 0.7881996221648082\n",
            "classification_report:                precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8806    0.9113    0.8956      6480\n",
            "           1     0.3795    0.3499    0.3641      1049\n",
            "           2     0.2795    0.1961    0.2305       362\n",
            "           3     0.5268    0.3986    0.4538       148\n",
            "\n",
            "    accuracy                         0.7964      8039\n",
            "   macro avg     0.5166    0.4640    0.4860      8039\n",
            "weighted avg     0.7816    0.7964    0.7882      8039\n",
            "\n",
            "[[5905  462   83   30]\n",
            " [ 596  367   77    9]\n",
            " [ 157  120   71   14]\n",
            " [  48   18   23   59]]\n",
            "0.9366160493571367\n",
            "##################################### Task End ############################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Zip and Download Models and Test Outputs after Training**\n"
      ],
      "metadata": {
        "id": "2g-t1QhQZ5OF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/drive/MyDrive/Experiments/DistilBERT/Models.zip /content/Depression-In-Tweets/Models\n",
        "!zip -r /content/drive/MyDrive/Experiments/DistilBERT/Output.zip /content/Depression-In-Tweets/Output\n",
        "!zip -r /content/drive/MyDrive/Experiments/DistilBERT/Figures.zip /content/Depression-In-Tweets/Figures"
      ],
      "metadata": {
        "id": "xAvvm_M4W244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0854d4fb-318f-4545-8951-7bd0536179d4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: content/Depression-In-Tweets/Models/ (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Models/distilbert-base-uncased_Best_Val_Acc.bin (deflated 8%)\n",
            "  adding: content/Depression-In-Tweets/Models/.gitkeep (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Output/ (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Output/distilbert-base-uncased---test_acc---0.7963677074262968.csv (deflated 61%)\n",
            "  adding: content/Depression-In-Tweets/Output/.gitkeep (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Figures/ (stored 0%)\n",
            "  adding: content/Depression-In-Tweets/Figures/distilbert-base-uncased---loss---.pdf (deflated 33%)\n",
            "  adding: content/Depression-In-Tweets/Figures/distilbert-base-uncased---acc---.pdf (deflated 34%)\n",
            "  adding: content/Depression-In-Tweets/Figures/distilbert-base-uncased---roc_auc_curve---.pdf (deflated 13%)\n",
            "  adding: content/Depression-In-Tweets/Figures/.gitkeep (stored 0%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation**"
      ],
      "metadata": {
        "id": "jUfbcHlCaADG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/Depression-In-Tweets/Scripts/evaluate.py --dataset_path /content/Depression-In-Tweets/Dataset/ --model_path /content/Depression-In-Tweets/Models/ --output_path /content/Depression-In-Tweets/Output/ --figure_path /content/Depression-In-Tweets/Figures/"
      ],
      "metadata": {
        "id": "9dLlPw9waDhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OhuL3XCJ9Jxb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}